{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL UNICOS desde XLSX Multi-Hoja\n",
    "\n",
    "Este notebook carga un archivo Excel con m√∫ltiples hojas, extrae registros de recurso\n",
    "(Equipos, Mano de Obra, Materiales, Transporte) clasificados por primera letra,\n",
    "y genera un DataFrame final UNICOS con deduplicaci√≥n y normalizaci√≥n.\n",
    "\n",
    "**Entrada**: Archivo .xlsx con 100+ hojas num√©ricas (001, 002, etc.) y auxiliares (Aux.01, etc.)\n",
    "\n",
    "**Salida**: DataFrame UNICOS con columnas normalizadas, sin duplicados, ordenado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìò Documento de Reglas y Contrato del ETL UNICOS\n",
    "\n",
    "### üéØ Objetivo\n",
    "Unificar recursos desde un Excel multi-hoja en un √∫nico dataset **UNICOS**, extrayendo **Equipos**, **Mano de Obra**, **Materiales** y **Transporte** con sus **unidades**, **precio unitario (tarifa)**, **CPC Elemento**, **NP/ND/EP** y **VAE (%)**.\n",
    "\n",
    "### ‚úÖ Contrato de Entrada (Excel)\n",
    "**Formato esperado**:\n",
    "- Archivo `.xlsx` con m√∫ltiples hojas.\n",
    "- Hojas num√©ricas con formato `###` (por defecto `001`, `002`, etc.).\n",
    "- Opcional: hojas auxiliares `Aux.*`.\n",
    "\n",
    "**Columnas requeridas (por letra)**:\n",
    "- **A ‚Üí Column1**: C√≥digo o identificador (se usa para clasificar recurso).\n",
    "- **B ‚Üí Column2**: C√≥digo alterno (si existe).\n",
    "- **C ‚Üí Column3**: Descripci√≥n.\n",
    "- **E ‚Üí Column5**: Tarifa (Equipos/Mano de Obra) o Unidad (Materiales/Transporte).\n",
    "- **G ‚Üí Column7**: Precio unitario (Materiales/Transporte).\n",
    "- **J ‚Üí Column10**: CPC Elemento.\n",
    "- **K ‚Üí Column11**: NP/ND/EP.\n",
    "- **L ‚Üí Column12**: VAE (%).\n",
    "\n",
    "**Filas inv√°lidas**:\n",
    "- Vac√≠as en descripci√≥n (Column3).\n",
    "- Encabezados de secci√≥n (EQUIPOS, MANO DE OBRA, MATERIALES, TRANSPORTE).\n",
    "\n",
    "### ‚öôÔ∏è Configuraci√≥n\n",
    "- `sheet_pattern`: regex para hojas num√©ricas. Default `^\\d{3}$`.\n",
    "- `max_sheet`: m√°ximo de hojas a procesar (0 = todas).\n",
    "- `include_aux`: incluir hojas `Aux.*`.\n",
    "- `include_otro`: incluir recursos sin clasificaci√≥n (OTRO).\n",
    "- `CODE_PATTERN`: regex para extraer c√≥digo si viene embebido en texto.\n",
    "\n",
    "### üß† Reglas de Clasificaci√≥n (RECURSO)\n",
    "Se clasifica por la **primera letra** del c√≥digo detectado:\n",
    "- `M` ‚Üí EQUIPO\n",
    "- `N` ‚Üí MANO DE OBRA\n",
    "- `O` ‚Üí MATERIAL\n",
    "- `P` ‚Üí TRANSPORTE\n",
    "- Otro ‚Üí OTRO\n",
    "\n",
    "### üîé Reglas de Extracci√≥n\n",
    "- **DESCRIPCION**: Column3 (limpia).\n",
    "- **PRECIO UNITARIO**:\n",
    "  - Equipos y Mano de Obra ‚Üí Column5 (tarifa/costo hora)\n",
    "  - Materiales y Transporte ‚Üí Column7 (precio unitario)\n",
    "- **UNIDAD**:\n",
    "  - Equipos y Mano de Obra ‚Üí vac√≠o\n",
    "  - Materiales y Transporte ‚Üí Column5\n",
    "- **CPC ELEMENTO**: Column10\n",
    "- **NP/ND/EP**: Column11\n",
    "- **VAE (%)**: Column12 (se mantiene como porcentaje num√©rico, ej. 40.0)\n",
    "\n",
    "> Equipos y Mano de Obra tienen adem√°s **Rendimiento (h/U)** en el Excel,\n",
    "> pero **no se exporta** en la salida final a menos que se solicite.\n",
    "\n",
    "### üîß Normalizaci√≥n\n",
    "- **N√∫meros**: acepta formatos `1,234.56`, `1.234,56`, `10%`.\n",
    "- **Texto**: se limpia con `strip()`.\n",
    "\n",
    "### üß© Agrupaci√≥n y Unificaci√≥n (UNICOS)\n",
    "- Se concatenan todas las hojas v√°lidas.\n",
    "- Se eliminan duplicados seg√∫n columnas finales.\n",
    "- Orden final por **DESCRIPCION**.\n",
    "\n",
    "### üì§ Salida Final (UNICOS)\n",
    "**Columnas esperadas** (sin c√≥digo ni hoja):\n",
    "- `DESCRIPCION`\n",
    "- `UNIDAD` (si aplica)\n",
    "- `PRECIO UNITARIO`\n",
    "- `CPC ELEMENTO`\n",
    "- `NP/ND/EP`\n",
    "- `VAE (%)`\n",
    "- `RECURSO`\n",
    "\n",
    "---\n",
    "\n",
    "### üó∫Ô∏è Diagrama del Flujo ETL (Mermaid)\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    A[Inicio] --> B[Cargar archivo Excel]\n",
    "    B --> C[Seleccionar hojas por patr√≥n ### y Aux.*]\n",
    "    C --> D[Leer columnas A,B,C,E,G,J,K,L]\n",
    "    D --> E[Filtrar filas inv√°lidas y encabezados]\n",
    "    E --> F[Detectar c√≥digo y clasificar recurso]\n",
    "    F --> G[Extraer descripci√≥n, unidad y precio unitario]\n",
    "    G --> H[Normalizar texto y n√∫meros]\n",
    "    H --> I[Concatenar todas las hojas]\n",
    "    I --> J[Eliminar duplicados]\n",
    "    J --> K[Ordenar por descripci√≥n]\n",
    "    K --> L[Exportar UNICOS]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SETUP: Instalando dependencias...\n",
      "============================================================\n",
      "Python executable: /home/codevars/Projects/ETL_EXCEL APUS/.venv/bin/python\n",
      "Python version: 3.12.3\n",
      "‚úì pandas ya est√° instalado\n",
      "‚úì numpy ya est√° instalado\n",
      "‚úì openpyxl ya est√° instalado\n",
      "‚úì ipywidgets ya est√° instalado\n",
      "\n",
      "‚è≥ Verificando python-calamine (lectura ultra-rapida)...\n",
      "‚Ñπ python-calamine no disponible (usando openpyxl)\n",
      "  Para instalar: pip install python-calamine\n",
      "\n",
      "‚è≥ Verificando itables (visor interactivo)...\n",
      "‚Ñπ itables no disponible\n",
      "  Para instalar: pip install itables\n",
      "\n",
      "============================================================\n",
      "‚úì Entorno configurado correctamente\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %% Setup de entorno\n",
    "# Esta celda prepara el entorno del notebook:\n",
    "# 1) Verifica/instala dependencias\n",
    "# 2) Detecta librerias opcionales\n",
    "# 3) Importa todo lo necesario para el ETL\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Set\n",
    "import warnings\n",
    "import subprocess\n",
    "import importlib.util\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SETUP: Instalando dependencias...\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version.split()[0]}\")\n",
    "\n",
    "# Paquetes requeridos para el flujo principal\n",
    "required_packages = {\n",
    "    'pandas': 'pandas',\n",
    "    'numpy': 'numpy',\n",
    "    'openpyxl': 'openpyxl',\n",
    "    'ipywidgets': 'ipywidgets',\n",
    "}\n",
    "\n",
    "def install_if_missing(package_name, import_name=None):\n",
    "    \"\"\"Instala el paquete solo si no existe en el kernel actual.\"\"\"\n",
    "    import_name = import_name or package_name\n",
    "    if importlib.util.find_spec(import_name) is not None:\n",
    "        print(f\"‚úì {package_name} ya est√° instalado\")\n",
    "        return\n",
    "\n",
    "    print(f\"‚è≥ Instalando {package_name}...\")\n",
    "    try:\n",
    "        # Importante: usar sys.executable asegura instalar en el mismo kernel\n",
    "        result = subprocess.run(\n",
    "            [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package_name],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True,\n",
    "        )\n",
    "        if result.stdout.strip():\n",
    "            print(result.stdout.strip())\n",
    "        if result.stderr.strip():\n",
    "            print(result.stderr.strip())\n",
    "        print(f\"‚úì {package_name} instalado\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚úó Error instalando {package_name}\")\n",
    "        if e.stdout:\n",
    "            print(e.stdout)\n",
    "        if e.stderr:\n",
    "            print(e.stderr)\n",
    "        raise\n",
    "\n",
    "    # Verificar import despu√©s de instalar\n",
    "    if importlib.util.find_spec(import_name) is None:\n",
    "        raise ImportError(f\"No se pudo importar {import_name} despu√©s de la instalaci√≥n\")\n",
    "\n",
    "# Instalar/verificar requeridos\n",
    "for pkg, imp in required_packages.items():\n",
    "    install_if_missing(pkg, imp)\n",
    "\n",
    "# Opcional: python-calamine para lectura ultra r√°pida\n",
    "print(\"\\n‚è≥ Verificando python-calamine (lectura ultra-rapida)...\")\n",
    "try:\n",
    "    import calamine\n",
    "    CALAMINE_AVAILABLE = True\n",
    "    print(\"‚úì python-calamine disponible\")\n",
    "except ImportError:\n",
    "    CALAMINE_AVAILABLE = False\n",
    "    print(\"‚Ñπ python-calamine no disponible (usando openpyxl)\")\n",
    "    print(\"  Para instalar: pip install python-calamine\")\n",
    "\n",
    "# Opcional: itables para visualizaci√≥n interactiva\n",
    "print(\"\\n‚è≥ Verificando itables (visor interactivo)...\")\n",
    "try:\n",
    "    import itables\n",
    "    ITABLES_AVAILABLE = True\n",
    "    print(\"‚úì itables disponible\")\n",
    "except ImportError:\n",
    "    ITABLES_AVAILABLE = False\n",
    "    print(\"‚Ñπ itables no disponible\")\n",
    "    print(\"  Para instalar: pip install itables\")\n",
    "\n",
    "# Importar dependencias luego de instalarlas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import FileUpload, VBox, HBox, Button, Label, HTML, Output, IntText, Text, Checkbox\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úì Entorno configurado correctamente\")\n",
    "print(\"=\"*60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìÅ CONFIGURACI√ìN DE CARPETAS\n",
      "======================================================================\n",
      "Carpeta de entrada: /home/codevars/Projects/ETL_EXCEL APUS/input\n",
      "Carpeta de salida: /home/codevars/Projects/ETL_EXCEL APUS/output\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0895e80e094e838e1f96323a5c66e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>üì• Carga de Archivo</h3>'), FileUpload(value=(), accept='.xlsx', description='üì§ ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "‚úÖ Carpeta de entrada configurada correctamente\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %% Configuraci√≥n de carpeta de entrada y carga de archivos\n",
    "\n",
    "import shutil\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Crear carpeta de entrada si no existe\n",
    "INPUT_FOLDER = Path('./input')\n",
    "INPUT_FOLDER.mkdir(exist_ok=True)\n",
    "\n",
    "OUTPUT_FOLDER = Path('./output')\n",
    "OUTPUT_FOLDER.mkdir(exist_ok=True)\n",
    "\n",
    "# Diccionario global para almacenar la ruta actual del archivo\n",
    "current_file_path = {'path': None}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìÅ CONFIGURACI√ìN DE CARPETAS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Carpeta de entrada: {INPUT_FOLDER.absolute()}\")\n",
    "print(f\"Carpeta de salida: {OUTPUT_FOLDER.absolute()}\")\n",
    "\n",
    "# UI para cargar archivo desde carpeta de entrada\n",
    "input_output = Output()\n",
    "input_status = Output()\n",
    "\n",
    "input_file_upload = FileUpload(\n",
    "    accept='.xlsx',\n",
    "    multiple=False,\n",
    "    description='üì§ Selecciona tu Excel:',\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "def list_input_files():\n",
    "    \"\"\"Lista archivos Excel en la carpeta de entrada.\"\"\"\n",
    "    excel_files = list(INPUT_FOLDER.glob('*.xlsx')) + list(INPUT_FOLDER.glob('*.xls'))\n",
    "    return excel_files\n",
    "\n",
    "def handle_input_upload(change):\n",
    "    \"\"\"Guarda el archivo en la carpeta de entrada.\"\"\"\n",
    "    input_status.clear_output()\n",
    "    if input_file_upload.value:\n",
    "        # ipywidgets >= 8.0 devuelve una tupla de diccionarios\n",
    "        uploaded_files = input_file_upload.value\n",
    "        if isinstance(uploaded_files, tuple):\n",
    "            for file_info in uploaded_files:\n",
    "                filename = file_info.get('name', 'archivo.xlsx')\n",
    "                content = file_info.get('content', b'')\n",
    "                input_path = INPUT_FOLDER / filename\n",
    "                with open(input_path, 'wb') as f:\n",
    "                    f.write(content)\n",
    "                current_file_path['path'] = str(input_path)\n",
    "                with input_status:\n",
    "                    print(f\"‚úÖ Archivo cargado: {filename}\")\n",
    "                    print(f\"üìç Ubicaci√≥n: {input_path.absolute()}\")\n",
    "        else:\n",
    "            # Versiones anteriores de ipywidgets\n",
    "            for filename, filedata in uploaded_files.items():\n",
    "                input_path = INPUT_FOLDER / filename\n",
    "                with open(input_path, 'wb') as f:\n",
    "                    f.write(filedata['content'])\n",
    "                current_file_path['path'] = str(input_path)\n",
    "                with input_status:\n",
    "                    print(f\"‚úÖ Archivo cargado: {filename}\")\n",
    "                    print(f\"üìç Ubicaci√≥n: {input_path.absolute()}\")\n",
    "\n",
    "input_file_upload.observe(handle_input_upload, names='value')\n",
    "\n",
    "# Bot√≥n para limpiar carpeta\n",
    "clean_button = Button(\n",
    "    description='üóëÔ∏è Limpiar entrada',\n",
    "    button_style='warning',\n",
    "    layout=widgets.Layout(width='150px')\n",
    ")\n",
    "\n",
    "def on_clean_click(b):\n",
    "    \"\"\"Limpia la carpeta de entrada.\"\"\"\n",
    "    with input_status:\n",
    "        input_status.clear_output()\n",
    "        try:\n",
    "            if list(INPUT_FOLDER.glob('*')):\n",
    "                shutil.rmtree(INPUT_FOLDER)\n",
    "                INPUT_FOLDER.mkdir(exist_ok=True)\n",
    "                current_file_path['path'] = None\n",
    "                print(\"‚úÖ Carpeta de entrada limpiada\")\n",
    "            else:\n",
    "                print(\"‚ÑπÔ∏è La carpeta ya est√° vac√≠a\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error al limpiar: {e}\")\n",
    "\n",
    "clean_button.on_click(on_clean_click)\n",
    "\n",
    "# Bot√≥n para listar archivos\n",
    "list_button = Button(\n",
    "    description='üìã Listar archivos',\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width='150px')\n",
    ")\n",
    "\n",
    "def on_list_click(b):\n",
    "    \"\"\"Lista los archivos en la carpeta de entrada.\"\"\"\n",
    "    with input_status:\n",
    "        input_status.clear_output()\n",
    "        files = list_input_files()\n",
    "        if files:\n",
    "            print(\"üìÇ Archivos en la carpeta de entrada:\\n\")\n",
    "            for i, f in enumerate(files, 1):\n",
    "                size_mb = f.stat().st_size / (1024*1024)\n",
    "                selected = \" ‚Üê SELECCIONADO\" if current_file_path['path'] == str(f) else \"\"\n",
    "                print(f\"  {i}. {f.name} ({size_mb:.2f} MB){selected}\")\n",
    "        else:\n",
    "            print(\"üì≠ No hay archivos Excel en la carpeta de entrada\")\n",
    "\n",
    "list_button.on_click(on_list_click)\n",
    "\n",
    "# Construir panel de carga\n",
    "input_ui = VBox([\n",
    "    HTML('<h3>üì• Carga de Archivo</h3>'),\n",
    "    input_file_upload,\n",
    "    HBox([clean_button, list_button]),\n",
    "    input_status\n",
    "])\n",
    "\n",
    "print(\"\\n\")\n",
    "display(input_ui)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Carpeta de entrada configurada correctamente\")\n",
    "print(\"=\"*70 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Configuraci√≥n global cargada\n"
     ]
    }
   ],
   "source": [
    "# %% Configuraci√≥n global\n",
    "# Mapeo de columnas del Excel hacia nombres internos\n",
    "# Nota: solo se leen columnas espec√≠ficas para optimizar rendimiento.\n",
    "COLUMN_MAPPING = {\n",
    "    'A': 'Column1',\n",
    "    'B': 'Column2',\n",
    "    'C': 'Column3',\n",
    "    'E': 'Column5',\n",
    "    'G': 'Column7',\n",
    "    'J': 'Column10',\n",
    "    'K': 'Column11',\n",
    "    'L': 'Column12',\n",
    "}\n",
    "\n",
    "# Clasificaci√≥n por primera letra\n",
    "RESOURCE_TYPE_MAP = {\n",
    "    'M': 'EQUIPO',\n",
    "    'N': 'MANO DE OBRA',\n",
    "    'O': 'MATERIAL',\n",
    "    'P': 'TRANSPORTE',\n",
    "}\n",
    "\n",
    "# Regex para detectar c√≥digos embebidos (ej: M.01, N02, O-03)\n",
    "CODE_PATTERN = r'([MNOP])\\s*[\\.-]?\\s*\\d+'\n",
    "\n",
    "# Patrones de encabezados que deben excluirse\n",
    "SECTION_HEADERS_PATTERNS = [\n",
    "    r'^EQUIPOS',\n",
    "    r'^MANO\\s+DE\\s+OBRA',\n",
    "    r'^MATERIALES?',\n",
    "    r'^TRANSPORTE',\n",
    "]\n",
    "\n",
    "def is_section_header(text: str) -> bool:\n",
    "    \"\"\"Detecta si un texto es un encabezado de secci√≥n.\"\"\"\n",
    "    if pd.isna(text) or text == '':\n",
    "        return False\n",
    "    text_upper = str(text).strip().upper()\n",
    "    for pattern in SECTION_HEADERS_PATTERNS:\n",
    "        if re.match(pattern, text_upper):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "print(\"‚úì Configuraci√≥n global cargada\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì export_results() disponible\n"
     ]
    }
   ],
   "source": [
    "# %% Exportaci√≥n\n",
    "def export_results():\n",
    "    \"\"\"Exporta UNICOS a CSV y XLSX.\"\"\"\n",
    "    global df_unicos\n",
    "\n",
    "    if 'df_unicos' not in globals() or df_unicos is None or df_unicos.empty:\n",
    "        print(\"‚ö† No hay resultados para exportar. Ejecuta primero el ETL.\")\n",
    "        return\n",
    "\n",
    "    csv_path = csv_path_text.value\n",
    "    xlsx_path = xlsx_path_text.value\n",
    "\n",
    "    try:\n",
    "        # Exportar CSV\n",
    "        df_unicos.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"‚úì CSV exportado: {csv_path}\")\n",
    "\n",
    "        # Exportar XLSX\n",
    "        with pd.ExcelWriter(xlsx_path, engine='openpyxl') as writer:\n",
    "            df_unicos.to_excel(writer, sheet_name='UNICOS', index=False)\n",
    "        print(f\"‚úì XLSX exportado: {xlsx_path}\")\n",
    "\n",
    "        print(f\"\\nüì¶ Archivos de salida:\")\n",
    "        print(f\"   CSV:  {os.path.abspath(csv_path)}\")\n",
    "        print(f\"   XLSX: {os.path.abspath(xlsx_path)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en exportaci√≥n: {e}\")\n",
    "\n",
    "print(\"‚úì export_results() disponible\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è Usando widget de carga (celda anterior)\n"
     ]
    }
   ],
   "source": [
    "# %% (Opcional) Carga directa desde ruta\n",
    "# Solo usa esto si prefieres especificar una ruta en lugar del widget\n",
    "# Deja vac√≠o para usar el widget de carga\n",
    "\n",
    "xlsx_path_manual = \"\"  # Ejemplo: \"input/mi_archivo.xlsx\"\n",
    "\n",
    "if xlsx_path_manual:\n",
    "    path_obj = Path(xlsx_path_manual)\n",
    "    if path_obj.exists():\n",
    "        current_file_path['path'] = str(path_obj.absolute())\n",
    "        print(f\"‚úì Ruta configurada: {path_obj.absolute()}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Archivo no encontrado: {xlsx_path_manual}\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Usando widget de carga (celda anterior)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì pick_sheets() cargado\n"
     ]
    }
   ],
   "source": [
    "# %% Funciones ETL - Selecci√≥n de hojas\n",
    "def pick_sheets(\n",
    "    xlsx_path: str,\n",
    "    sheet_pattern: str = r'^\\d{3}$',\n",
    "    max_sheet: int = None,\n",
    "    include_aux: bool = True\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Selecciona hojas seg√∫n patr√≥n regex y l√≠mite.\n",
    "    Respeta el orden original del archivo.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        excel_file = pd.ExcelFile(xlsx_path)\n",
    "        all_sheets = excel_file.sheet_names\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error abriendo {xlsx_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "    # Compilar regex del patr√≥n de hojas\n",
    "    try:\n",
    "        pattern = re.compile(sheet_pattern)\n",
    "    except Exception:\n",
    "        print(f\"‚ùå Patr√≥n regex inv√°lido: {sheet_pattern}\")\n",
    "        return []\n",
    "\n",
    "    # Hojas num√©ricas (seg√∫n patr√≥n)\n",
    "    numeric_sheets = [s for s in all_sheets if pattern.match(s)]\n",
    "\n",
    "    # Hojas auxiliares\n",
    "    aux_sheets = [s for s in all_sheets if s.startswith('Aux.')] if include_aux else []\n",
    "\n",
    "    # Combinar respetando orden original del archivo\n",
    "    selected = [s for s in all_sheets if s in numeric_sheets or s in aux_sheets]\n",
    "\n",
    "    # Limitar cantidad de hojas si se pide\n",
    "    if max_sheet and max_sheet > 0:\n",
    "        selected = selected[:max_sheet]\n",
    "\n",
    "    return selected\n",
    "\n",
    "print(\"‚úì pick_sheets() cargado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì read_sheet_fast() cargado\n"
     ]
    }
   ],
   "source": [
    "# %% Funciones ETL - Lectura eficiente\n",
    "def read_sheet_fast(\n",
    "    xlsx_path: str,\n",
    "    sheet_name: str,\n",
    "    column_mapping: Dict[str, str] = COLUMN_MAPPING\n",
    ") -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Lee solo columnas necesarias de una hoja.\n",
    "    Intenta calamine primero (r√°pido), fallback a openpyxl.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Intentar con python-calamine si est√° disponible\n",
    "        if CALAMINE_AVAILABLE:\n",
    "            try:\n",
    "                from calamine import load_workbook\n",
    "                wb = load_workbook(xlsx_path)\n",
    "                ws = wb.sheet_by_name(sheet_name)\n",
    "\n",
    "                # Indices 0-based para columnas A, B, C, E, G, J, K, L\n",
    "                col_indices = {'A': 0, 'B': 1, 'C': 2, 'E': 4, 'G': 6, 'J': 9, 'K': 10, 'L': 11}\n",
    "                data = {}\n",
    "\n",
    "                for col_letter, col_name in column_mapping.items():\n",
    "                    col_idx = col_indices[col_letter]\n",
    "                    col_data = []\n",
    "                    for row in ws.rows():\n",
    "                        if col_idx < len(row):\n",
    "                            cell = row[col_idx]\n",
    "                            col_data.append(cell.value if hasattr(cell, 'value') else cell)\n",
    "                        else:\n",
    "                            col_data.append(None)\n",
    "                    data[col_name] = col_data\n",
    "\n",
    "                df = pd.DataFrame(data)\n",
    "                return df\n",
    "            except Exception:\n",
    "                # Si falla calamine, se intenta openpyxl\n",
    "                pass\n",
    "\n",
    "        # Fallback: openpyxl\n",
    "        from openpyxl import load_workbook\n",
    "        wb = load_workbook(xlsx_path, data_only=True, read_only=True)\n",
    "        ws = wb[sheet_name]\n",
    "\n",
    "        # Construir columnas vac√≠as\n",
    "        col_letters = list(column_mapping.keys())\n",
    "        data = {column_mapping[col]: [] for col in col_letters}\n",
    "\n",
    "        # Recorrer filas y extraer columnas clave\n",
    "        for row in ws.iter_rows(min_col=1, max_col=12, values_only=False):\n",
    "            for col_letter, col_name in column_mapping.items():\n",
    "                col_idx = ord(col_letter) - ord('A')\n",
    "                if col_idx < len(row):\n",
    "                    cell = row[col_idx]\n",
    "                    value = cell.value if hasattr(cell, 'value') else cell\n",
    "                    data[col_name].append(value)\n",
    "                else:\n",
    "                    data[col_name].append(None)\n",
    "\n",
    "        wb.close()\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "\n",
    "    except Exception:\n",
    "        # En caso de fallo, devolvemos None para que el flujo contin√∫e\n",
    "        return None\n",
    "\n",
    "print(\"‚úì read_sheet_fast() cargado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Funciones de filtrado cargadas\n"
     ]
    }
   ],
   "source": [
    "# %% Funciones ETL - Filtrado y clasificaci√≥n\n",
    "def filter_rows(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Excluye:\n",
    "    - Filas con descripci√≥n vac√≠a (Column3)\n",
    "    - Encabezados de secci√≥n\n",
    "    \"\"\"\n",
    "    # Filtrar nulos/vac√≠os en descripci√≥n\n",
    "    df = df[df['Column3'].notna() & (df['Column3'] != '')]\n",
    "\n",
    "    # Excluir encabezados de secci√≥n (por Column1 o Column3)\n",
    "    df = df[~df['Column1'].astype(str).apply(is_section_header)]\n",
    "    df = df[~df['Column3'].astype(str).apply(is_section_header)]\n",
    "\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def extract_code(row_dict: Dict) -> str:\n",
    "    \"\"\"\n",
    "    Intenta extraer el c√≥digo desde Column1/Column2/Column3.\n",
    "    Si no encuentra patr√≥n, devuelve texto normalizado del campo m√°s confiable.\n",
    "    \"\"\"\n",
    "    candidates = [row_dict.get('Column1', ''), row_dict.get('Column2', ''), row_dict.get('Column3', '')]\n",
    "    for val in candidates:\n",
    "        if pd.isna(val) or val == '':\n",
    "            continue\n",
    "        m = re.search(CODE_PATTERN, str(val).upper())\n",
    "        if m:\n",
    "            return m.group(0).replace(' ', '')\n",
    "\n",
    "    # Fallback: usar Column1/Column2 sin patr√≥n\n",
    "    fallback = normalize_text_field(row_dict.get('Column1', '')) or normalize_text_field(row_dict.get('Column2', ''))\n",
    "    return fallback\n",
    "\n",
    "def classify_resource(code_or_text: str) -> str:\n",
    "    \"\"\"Clasifica recurso por primera letra encontrada.\"\"\"\n",
    "    text = str(code_or_text).upper() if code_or_text else ''\n",
    "    if text:\n",
    "        letter = text[0]\n",
    "        return RESOURCE_TYPE_MAP.get(letter, 'OTRO')\n",
    "    return 'OTRO'\n",
    "\n",
    "def normalize_numeric(value, is_percentage=False) -> float:\n",
    "    \"\"\"\n",
    "    Normaliza valores num√©ricos con m√∫ltiples formatos:\n",
    "    - \"1,234.56\", \"1.234,56\", \"1234,56\", \"1234.56\", \"10%\", \"0.1\"\n",
    "\n",
    "    Nota: si is_percentage=True, convierte 40 -> 0.40\n",
    "    \"\"\"\n",
    "    if pd.isna(value) or value == '':\n",
    "        return 0.0\n",
    "\n",
    "    value_str = str(value).strip()\n",
    "\n",
    "    # Quitar s√≠mbolo % si existe (pero no convertir autom√°ticamente)\n",
    "    if '%' in value_str:\n",
    "        value_str = value_str.replace('%', '').strip()\n",
    "\n",
    "    # Detectar separador decimal (coma o punto)\n",
    "    comma_count = value_str.count(',')\n",
    "    dot_count = value_str.count('.')\n",
    "\n",
    "    try:\n",
    "        if comma_count > 1 or dot_count > 1:\n",
    "            if ',' in value_str and '.' in value_str:\n",
    "                # Decide si el √∫ltimo separador es decimal\n",
    "                if value_str.rindex(',') > value_str.rindex('.'):\n",
    "                    # Formato: 1.234,56\n",
    "                    value_str = value_str.replace('.', '').replace(',', '.')\n",
    "                else:\n",
    "                    # Formato: 1,234.56\n",
    "                    value_str = value_str.replace(',', '')\n",
    "            elif comma_count > 1:\n",
    "                # M√∫ltiples comas: las primeras son miles\n",
    "                value_str = value_str.replace(',', '.', comma_count - 1).replace(',', '.')\n",
    "        elif comma_count == 1 and dot_count == 0:\n",
    "            # Podr√≠a ser 1,5 o 1.500 dependiendo del locale\n",
    "            parts = value_str.split(',')\n",
    "            if len(parts[1]) > 2:\n",
    "                value_str = value_str.replace(',', '')\n",
    "            else:\n",
    "                value_str = value_str.replace(',', '.')\n",
    "\n",
    "        result = float(value_str)\n",
    "\n",
    "        # Si se pide convertir porcentaje a fracci√≥n\n",
    "        if is_percentage:\n",
    "            result = result / 100.0\n",
    "\n",
    "        return result\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "def normalize_text_field(value) -> str:\n",
    "    \"\"\"Normaliza campos de texto.\"\"\"\n",
    "    if pd.isna(value) or value == '':\n",
    "        return ''\n",
    "    return str(value).strip()\n",
    "\n",
    "print(\"‚úì Funciones de filtrado cargadas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì process_row() cargado\n"
     ]
    }
   ],
   "source": [
    "# %% Funciones ETL - Procesamiento de filas\n",
    "def process_row(row_dict: Dict) -> Optional[Dict]:\n",
    "    \"\"\"Procesa una fila y devuelve dict normalizado o None si no es v√°lida.\"\"\"\n",
    "    try:\n",
    "        # Extraer columnas seg√∫n el mapeo\n",
    "        col1 = row_dict.get('Column1', '')\n",
    "        col2 = row_dict.get('Column2', '')\n",
    "        col3 = row_dict.get('Column3', '')\n",
    "        col5 = row_dict.get('Column5', '')\n",
    "        col7 = row_dict.get('Column7', '')\n",
    "        col10 = row_dict.get('Column10', '')\n",
    "        col11 = row_dict.get('Column11', '')\n",
    "        col12 = row_dict.get('Column12', '')\n",
    "\n",
    "        # Validaci√≥n: debe haber descripci√≥n\n",
    "        if pd.isna(col3) or col3 == '':\n",
    "            return None\n",
    "\n",
    "        # Excluir encabezados\n",
    "        if is_section_header(col1) or is_section_header(col3):\n",
    "            return None\n",
    "\n",
    "        # Detectar c√≥digo y clasificar recurso\n",
    "        codigo = extract_code(row_dict)\n",
    "        recurso = classify_resource(codigo)\n",
    "\n",
    "        # DESCRIPCION\n",
    "        descripcion = normalize_text_field(col3)\n",
    "\n",
    "        # PRECIO UNITARIO y UNIDAD seg√∫n RECURSO\n",
    "        if recurso in ('EQUIPO', 'MANO DE OBRA'):\n",
    "            # Tarifa/costo hora\n",
    "            precio_unitario = normalize_numeric(col5)\n",
    "            unidad = ''\n",
    "        else:  # MATERIAL, TRANSPORTE, OTRO\n",
    "            precio_unitario = normalize_numeric(col7)\n",
    "            unidad = normalize_text_field(col5)\n",
    "\n",
    "        # Otros campos\n",
    "        cpc = normalize_text_field(col10)\n",
    "        np_nd = normalize_text_field(col11)\n",
    "        vae = normalize_numeric(col12, is_percentage=False)\n",
    "\n",
    "        result = {\n",
    "            'DESCRIPCION': descripcion,\n",
    "            'UNIDAD': unidad,\n",
    "            'PRECIO UNITARIO': precio_unitario,\n",
    "            'CPC ELEMENTO': cpc,\n",
    "            'NP/ND/EP': np_nd if np_nd else '',\n",
    "            'VAE (%)': vae,\n",
    "            'RECURSO': recurso\n",
    "        }\n",
    "\n",
    "        return result\n",
    "    except Exception:\n",
    "        # Si algo falla en una fila, no detener todo el ETL\n",
    "        return None\n",
    "\n",
    "print(\"‚úì process_row() cargado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì build_unicos() cargado\n"
     ]
    }
   ],
   "source": [
    "# %% Funciones ETL - Construcci√≥n del dataset UNICOS\n",
    "def build_unicos(\n",
    "    all_rows: List[Dict],\n",
    "    include_otro: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Construye DataFrame UNICOS final:\n",
    "    - Concatena todas las filas\n",
    "    - Deduplicaci√≥n\n",
    "    - Normalizaci√≥n\n",
    "    - Ordenamiento\n",
    "    \"\"\"\n",
    "    if not all_rows:\n",
    "        print(\"‚ùå No hay filas para procesar\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(all_rows)\n",
    "\n",
    "    # Excluir OTRO si aplica\n",
    "    if not include_otro:\n",
    "        df = df[df['RECURSO'] != 'OTRO']\n",
    "\n",
    "    # Columnas finales (sin CODIGO ni HOJA)\n",
    "    final_cols = ['DESCRIPCION', 'UNIDAD', 'PRECIO UNITARIO', 'CPC ELEMENTO', 'NP/ND/EP', 'VAE (%)', 'RECURSO']\n",
    "    df = df[final_cols]\n",
    "\n",
    "    # Deduplicaci√≥n exacta de filas\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Normalizaci√≥n post-dedup\n",
    "    df['NP/ND/EP'] = df['NP/ND/EP'].fillna('').astype(str)\n",
    "    df['VAE (%)'] = df['VAE (%)'].fillna(0).astype(float)\n",
    "    df['PRECIO UNITARIO'] = df['PRECIO UNITARIO'].fillna(0).astype(float)\n",
    "    df['UNIDAD'] = df['UNIDAD'].fillna('').astype(str)\n",
    "\n",
    "    # Ordenar por DESCRIPCION\n",
    "    df = df.sort_values('DESCRIPCION', ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"‚úì build_unicos() cargado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì run_etl() cargado\n"
     ]
    }
   ],
   "source": [
    "# %% Ejecuci√≥n del ETL\n",
    "def run_etl(\n",
    "    xlsx_path: str,\n",
    "    max_sheet: int = None,\n",
    "    include_aux: bool = True,\n",
    "    include_otro: bool = False,\n",
    "    sheet_pattern: str = r'^\\d{3}$'\n",
    ") -> Tuple[pd.DataFrame, Dict]:\n",
    "    \"\"\"\n",
    "    Ejecuta el pipeline ETL completo.\n",
    "    Devuelve (df_unicos, stats_dict)\n",
    "    \"\"\"\n",
    "    stats = {\n",
    "        'total_sheets': 0,\n",
    "        'sheets_ok': 0,\n",
    "        'sheets_failed': 0,\n",
    "        'total_rows_extracted': 0,\n",
    "        'duplicates_removed': 0,\n",
    "        'final_rows': 0,\n",
    "        'time_seconds': 0\n",
    "    }\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 1. Seleccionar hojas\n",
    "    sheets_to_process = pick_sheets(\n",
    "        xlsx_path,\n",
    "        sheet_pattern=sheet_pattern,\n",
    "        max_sheet=max_sheet,\n",
    "        include_aux=include_aux\n",
    "    )\n",
    "\n",
    "    stats['total_sheets'] = len(sheets_to_process)\n",
    "    print(f\"\\nüìä Hojas a procesar: {stats['total_sheets']}\")\n",
    "    print(f\"   Patr√≥n: {sheet_pattern}\")\n",
    "    print(f\"   Include Aux: {include_aux}\")\n",
    "    print(f\"   Max: {max_sheet if max_sheet and max_sheet > 0 else 'todas'}\\n\")\n",
    "\n",
    "    all_rows = []\n",
    "\n",
    "    # 2. Procesar cada hoja\n",
    "    for i, sheet_name in enumerate(sheets_to_process, 1):\n",
    "        print(f\"[{i:3d}/{stats['total_sheets']}] Leyendo '{sheet_name}'...\", end=' ')\n",
    "\n",
    "        df = read_sheet_fast(xlsx_path, sheet_name)\n",
    "\n",
    "        if df is None or df.empty:\n",
    "            print(\"‚ö† Vac√≠a o error\")\n",
    "            stats['sheets_failed'] += 1\n",
    "            continue\n",
    "\n",
    "        # Filtrar filas v√°lidas\n",
    "        df = filter_rows(df)\n",
    "\n",
    "        if df.empty:\n",
    "            print(\"‚ö† Sin filas v√°lidas\")\n",
    "            stats['sheets_failed'] += 1\n",
    "            continue\n",
    "\n",
    "        # Procesar cada fila\n",
    "        sheet_rows = 0\n",
    "        for _, row in df.iterrows():\n",
    "            processed = process_row(row.to_dict())\n",
    "            if processed:\n",
    "                all_rows.append(processed)\n",
    "                sheet_rows += 1\n",
    "\n",
    "        stats['sheets_ok'] += 1\n",
    "        stats['total_rows_extracted'] += sheet_rows\n",
    "        print(f\"‚úì {sheet_rows} filas\")\n",
    "\n",
    "    # 3. Construir UNICOS\n",
    "    print(f\"\\nüîÑ Deduplicando {stats['total_rows_extracted']} filas...\")\n",
    "    df_unicos = build_unicos(all_rows, include_otro=include_otro)\n",
    "\n",
    "    stats['final_rows'] = len(df_unicos)\n",
    "    stats['duplicates_removed'] = stats['total_rows_extracted'] - stats['final_rows']\n",
    "    stats['time_seconds'] = time.time() - start_time\n",
    "\n",
    "    print(f\"\\nüìà Resultados:\")\n",
    "    print(f\"   Hojas procesadas: {stats['sheets_ok']}/{stats['total_sheets']}\")\n",
    "    print(f\"   Filas extra√≠das: {stats['total_rows_extracted']}\")\n",
    "    print(f\"   Duplicados removidos: {stats['duplicates_removed']}\")\n",
    "    print(f\"   Filas finales (UNICOS): {stats['final_rows']}\")\n",
    "    print(f\"   Tiempo: {stats['time_seconds']:.2f}s\")\n",
    "\n",
    "    return df_unicos, stats\n",
    "\n",
    "print(\"‚úì run_etl() cargado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Callback ejecutar ETL asignado\n"
     ]
    }
   ],
   "source": [
    "# %% Callback para ejecutar ETL\n",
    "def on_execute_click(b):\n",
    "    # Limpiar salida previa\n",
    "    output_status.clear_output()\n",
    "\n",
    "    # Determinar ruta\n",
    "    xlsx_path = manual_path_text.value.strip() if manual_path_text.value.strip() else current_file_path['path']\n",
    "\n",
    "    if not xlsx_path:\n",
    "        with output_status:\n",
    "            print(\"‚ùå Por favor sube un archivo o ingresa una ruta manual\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(xlsx_path):\n",
    "        with output_status:\n",
    "            print(f\"‚ùå Archivo no encontrado: {xlsx_path}\")\n",
    "        return\n",
    "\n",
    "    with output_status:\n",
    "        try:\n",
    "            # Par√°metros desde UI\n",
    "            max_sheet = max_sheet_input.value if max_sheet_input.value > 0 else None\n",
    "            include_aux = include_aux_checkbox.value\n",
    "            include_otro = include_otro_checkbox.value\n",
    "            sheet_pattern = sheet_pattern_text.value\n",
    "            csv_path = csv_path_text.value\n",
    "            xlsx_path_export = xlsx_path_text.value\n",
    "\n",
    "            # Ejecutar ETL\n",
    "            df_unicos, stats = run_etl(\n",
    "                xlsx_path,\n",
    "                max_sheet=max_sheet,\n",
    "                include_aux=include_aux,\n",
    "                include_otro=include_otro,\n",
    "                sheet_pattern=sheet_pattern\n",
    "            )\n",
    "\n",
    "            # Guardar resultado en variables globales\n",
    "            globals()['df_unicos'] = df_unicos\n",
    "            globals()['etl_stats'] = stats\n",
    "\n",
    "            print(\"\\n‚úì ETL ejecutado exitosamente\")\n",
    "\n",
    "            # Vista previa\n",
    "            print(\"\\nüìã Primeras 10 filas:\")\n",
    "            cols_preview = ['DESCRIPCION', 'UNIDAD', 'PRECIO UNITARIO', 'CPC ELEMENTO', 'NP/ND/EP', 'VAE (%)', 'RECURSO']\n",
    "            print(df_unicos[cols_preview].head(10).to_string(index=False))\n",
    "\n",
    "            # Distribuci√≥n por recurso\n",
    "            print(\"\\nüìä Distribuci√≥n por RECURSO:\")\n",
    "            print(df_unicos['RECURSO'].value_counts().to_string())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error en ETL: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "# Enlazar bot√≥n con el callback\n",
    "execute_button.on_click(on_execute_click)\n",
    "\n",
    "print(\"‚úì Callback ejecutar ETL asignado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üîç VERIFICACI√ìN DEL SISTEMA\n",
      "======================================================================\n",
      "\n",
      "1Ô∏è‚É£ ARCHIVO CARGADO:\n",
      "   ‚úÖ input/00 APUS 9.2 E.T. OTRA VERSI√ìN.xlsx\n",
      "   üì¶ Tama√±o: 3.79 MB\n",
      "   üìã Total hojas: 595\n",
      "   üìã Primeras 5: ['Datos', 'PRES.', 'UNICOS', '√çNDICE', '001']\n",
      "\n",
      "2Ô∏è‚É£ FUNCIONES CARGADAS:\n",
      "   ‚úÖ pick_sheets()\n",
      "   ‚úÖ read_sheet_fast()\n",
      "   ‚úÖ filter_rows()\n",
      "   ‚úÖ run_etl()\n",
      "   ‚úÖ build_unicos()\n",
      "\n",
      "3Ô∏è‚É£ VARIABLES:\n",
      "   INPUT_FOLDER: /home/codevars/Projects/ETL_EXCEL APUS/input\n",
      "   OUTPUT_FOLDER: /home/codevars/Projects/ETL_EXCEL APUS/output\n",
      "\n",
      "======================================================================\n",
      "\n",
      "üöÄ ¬øQuieres ejecutar el ETL ahora?\n",
      "   Descomenta las l√≠neas de abajo y ejecuta esta celda nuevamente\n",
      "\n",
      "--- DESCOMENTA ESTO PARA EJECUTAR ---\n",
      "df_unicos, etl_stats = run_etl(\n",
      "    current_file_path['path'],\n",
      "    max_sheet=5,  # Solo 5 hojas para prueba r√°pida\n",
      "    include_aux=True,\n",
      "    include_otro=False,\n",
      "    sheet_pattern=r'^\\d{3}$'\n",
      ")\n",
      "print(\"\\n‚úÖ ETL completado! Resultado en: df_unicos\")\n",
      "display(df_unicos.head(10))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %% ‚ö° VERIFICACI√ìN Y EJECUCI√ìN DIRECTA\n",
    "# Esta celda te permite ejecutar el ETL SIN usar el bot√≥n\n",
    "# √ötil para verificar que todo funciona\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üîç VERIFICACI√ìN DEL SISTEMA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Verificar archivo cargado\n",
    "print(\"\\n1Ô∏è‚É£ ARCHIVO CARGADO:\")\n",
    "if current_file_path.get('path'):\n",
    "    archivo = current_file_path['path']\n",
    "    if os.path.exists(archivo):\n",
    "        size_mb = os.path.getsize(archivo) / (1024*1024)\n",
    "        print(f\"   ‚úÖ {archivo}\")\n",
    "        print(f\"   üì¶ Tama√±o: {size_mb:.2f} MB\")\n",
    "        \n",
    "        # Mostrar hojas del archivo\n",
    "        try:\n",
    "            excel = pd.ExcelFile(archivo)\n",
    "            print(f\"   üìã Total hojas: {len(excel.sheet_names)}\")\n",
    "            print(f\"   üìã Primeras 5: {excel.sheet_names[:5]}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Error leyendo hojas: {e}\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå Archivo no existe: {archivo}\")\n",
    "else:\n",
    "    print(\"   ‚ùå No hay archivo cargado\")\n",
    "    print(\"   üëÜ Sube un archivo en la celda 2 (widget de carga)\")\n",
    "\n",
    "# 2. Verificar funciones cargadas\n",
    "print(\"\\n2Ô∏è‚É£ FUNCIONES CARGADAS:\")\n",
    "funciones = ['pick_sheets', 'read_sheet_fast', 'filter_rows', 'run_etl', 'build_unicos']\n",
    "for f in funciones:\n",
    "    if f in dir():\n",
    "        print(f\"   ‚úÖ {f}()\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå {f}() - FALTA EJECUTAR CELDAS ANTERIORES\")\n",
    "\n",
    "# 3. Verificar variables globales\n",
    "print(\"\\n3Ô∏è‚É£ VARIABLES:\")\n",
    "print(f\"   INPUT_FOLDER: {INPUT_FOLDER.absolute() if 'INPUT_FOLDER' in dir() else '‚ùå No definida'}\")\n",
    "print(f\"   OUTPUT_FOLDER: {OUTPUT_FOLDER.absolute() if 'OUTPUT_FOLDER' in dir() else '‚ùå No definida'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "# EJECUCI√ìN DIRECTA (descomenta para ejecutar sin bot√≥n)\n",
    "if current_file_path.get('path') and os.path.exists(current_file_path['path']):\n",
    "    print(\"\\nüöÄ ¬øQuieres ejecutar el ETL ahora?\")\n",
    "    print(\"   Descomenta las l√≠neas de abajo y ejecuta esta celda nuevamente\")\n",
    "    print(\"\"\"\n",
    "--- DESCOMENTA ESTO PARA EJECUTAR ---\n",
    "df_unicos, etl_stats = run_etl(\n",
    "    current_file_path['path'],\n",
    "    max_sheet=5,  # Solo 5 hojas para prueba r√°pida\n",
    "    include_aux=True,\n",
    "    include_otro=False,\n",
    "    sheet_pattern=r'^\\\\d{3}$'\n",
    ")\n",
    "print(\"\\\\n‚úÖ ETL completado! Resultado en: df_unicos\")\n",
    "display(df_unicos.head(10))\n",
    "\"\"\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Primero carga un archivo Excel para poder ejecutar el ETL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì display_results() disponible\n"
     ]
    }
   ],
   "source": [
    "# %% Visor interactivo de resultados\n",
    "def display_results():\n",
    "    \"\"\"Muestra resultados del ETL en formato interactivo.\"\"\"\n",
    "    global df_unicos\n",
    "\n",
    "    if 'df_unicos' not in globals() or df_unicos is None or df_unicos.empty:\n",
    "        print(\"‚ö† Ejecuta primero el ETL (bot√≥n verde)\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Dataset UNICOS - {len(df_unicos)} filas totales\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    if ITABLES_AVAILABLE:\n",
    "        print(\"üìä Usando visor interactivo itables (b√∫squeda, ordenamiento, paginaci√≥n)\\n\")\n",
    "        itables.show(df_unicos, maxRows=500)\n",
    "    else:\n",
    "        print(\"üìä Visor est√°ndar (primeras 50 filas):\\n\")\n",
    "        pd.set_option('display.max_rows', 50)\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.width', None)\n",
    "        display(df_unicos)\n",
    "        pd.reset_option('display.max_rows')\n",
    "\n",
    "print(\"‚úì display_results() disponible\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì export_results() disponible\n"
     ]
    }
   ],
   "source": [
    "# %% Exportaci√≥n de resultados\n",
    "def export_results(include_hoja_column: bool = False):\n",
    "    \"\"\"\n",
    "    Exporta los resultados del ETL a CSV y XLSX.\n",
    "    \n",
    "    Args:\n",
    "        include_hoja_column: Si True, incluye la columna HOJA en los archivos\n",
    "    \"\"\"\n",
    "    if 'df_unicos' not in globals() or df_unicos is None or len(df_unicos) == 0:\n",
    "        print(\"‚ö†Ô∏è No hay resultados para exportar\")\n",
    "        print(\"Ejecuta primero el ETL\")\n",
    "        return\n",
    "\n",
    "    csv_path = Path(csv_path_text.value)\n",
    "    xlsx_path = Path(xlsx_path_text.value)\n",
    "\n",
    "    # Asegurar que existan las carpetas\n",
    "    csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    xlsx_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Preparar datos para exportar\n",
    "    df_export = df_unicos.copy()\n",
    "    if not include_hoja_column and 'HOJA' in df_export.columns:\n",
    "        df_export = df_export.drop(columns=['HOJA'])\n",
    "\n",
    "    try:\n",
    "        # Exportar CSV\n",
    "        df_export.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"‚úÖ CSV: {csv_path.absolute()}\")\n",
    "\n",
    "        # Exportar XLSX\n",
    "        with pd.ExcelWriter(xlsx_path, engine='openpyxl') as writer:\n",
    "            df_export.to_excel(writer, sheet_name='UNICOS', index=False)\n",
    "        print(f\"‚úÖ XLSX: {xlsx_path.absolute()}\")\n",
    "\n",
    "        print(f\"\\nüì¶ Archivos guardados en carpeta: {OUTPUT_FOLDER.absolute()}\")\n",
    "        \n",
    "        # Mostrar tama√±os de archivo\n",
    "        if csv_path.exists():\n",
    "            csv_size = csv_path.stat().st_size / 1024\n",
    "            print(f\"   üìÑ CSV: {csv_size:.2f} KB\")\n",
    "        if xlsx_path.exists():\n",
    "            xlsx_size = xlsx_path.stat().st_size / 1024\n",
    "            print(f\"   üìä XLSX: {xlsx_size:.2f} KB\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en exportaci√≥n: {e}\")\n",
    "\n",
    "print(\"‚úì export_results() disponible\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Resumen de uso\n",
    "\n",
    "### Flujo completo:\n",
    "1. **Ejecuta todas las celdas** desde el principio (Setup ‚Üí Carga ‚Üí Configuraci√≥n ‚Üí Funciones ‚Üí Callback)\n",
    "2. **Sube tu archivo Excel** usando el widget de carga\n",
    "3. **Configura par√°metros** si es necesario\n",
    "4. **Presiona \"‚ñ∂Ô∏è Ejecutar ETL\"**\n",
    "5. **Ve los resultados** con `display_results()`\n",
    "6. **Exporta** con `export_results()`\n",
    "\n",
    "### Comandos √∫tiles despu√©s del ETL:\n",
    "```python\n",
    "# Ver resultados\n",
    "display_results()\n",
    "\n",
    "# Exportar a CSV y XLSX\n",
    "export_results()\n",
    "\n",
    "# Exportar incluyendo columna HOJA\n",
    "export_results(include_hoja_column=True)\n",
    "\n",
    "# Ver estad√≠sticas\n",
    "print(etl_stats)\n",
    "\n",
    "# Filtrar solo EQUIPOS\n",
    "df_equipos = df_unicos[df_unicos['RECURSO'] == 'EQUIPO']\n",
    "print(f\"Total EQUIPOS: {len(df_equipos)}\")\n",
    "\n",
    "# Buscar por descripci√≥n\n",
    "df_search = df_unicos[df_unicos['DESCRIPCION'].str.contains('MOTOR', case=False)]\n",
    "display(df_search)\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
